### Alexey — Data Engineer & Systems Analyst

Remote-ready for international teams; async by default; clear written comms. Builds reliable data platforms and analytics that ship business value.

**Core stack:** Python, SQL, Polars, PySpark, FastAPI, Kafka, Airflow, ClickHouse, Iceberg, Debezium, Docker, GitLab, Power BI, Grafana, Streamlit.
**Focus:** data modeling, ETL/ELT, CDC, lakehouse design, documentation, observability, cost and performance hygiene.
**Work mode:** full-time or contractor, fully remote, overlap with Europe and the Americas.

#### VTB — Systems Analyst

* Built a lakehouse on object storage with Iceberg for enterprise use.
* Wrote architecture docs, playbooks, runbooks, data contracts, and recovery objectives in a Confluence-style portal.
* Described ETL flows in BPMN and UML to satisfy regulatory audits.
* Designed models, integrations, and marts using the Data Vault approach.
* Set up ingest from Oracle to Kafka to object storage to Iceberg with CDC via Debezium and batch loads for historical layers.

#### Samokat — Data Engineer

* Simplified sales ETL and forecasting pipelines to improve accuracy and reduce stock costs.
* Migrated complex jobs between Pandas, Polars, and PySpark where pragmatic.
* Delivered production data marts in ClickHouse, including write-off analytics.
* Orchestrated DWH loads from object storage, MSSQL, Hive and files with Airflow; supported full, incremental, and CDC patterns.
* Shipped Streamlit dashboards with custom filters and KPI views.
* Set up CI and CD with linters and GitLab; containerized ETL, ClickHouse and apps with Docker.
* Explored Data Vault and Anchor modeling; tuned pipelines to lower infra load.

#### AEB Bank — Data & Analytics

* Ran A/B experiments for credit offers in SMS and in-app banners; selected winning variants with product teams.
* Automated financial reporting to cut manual effort and improve data quality.
* Built Power BI dashboards for key finance metrics.
* With engineering, delivered Grafana dashboards for near-real-time sales; automated ingestion with Airflow; processed data in Pandas; deployed on Docker and Linux.

---

If you want, I can compress this into a one-screen LinkedIn summary or tailor it to a specific remote job post.
